# Oak Ridge CUDA course

| Homework | Key Concepts and Skills Acquired                                                                                   |
|----------|-------------------------------------------------------------------------------------------------------------------|
| HW1      | Fundamentals of CUDA programming: kernel launches, device memory allocation, host-device data transfer, 1D/2D thread/block indexing, and basic error checking. |
| HW2      | Shared memory usage in CUDA: implementing 1D stencils and optimizing 2D matrix multiplication with shared memory for performance gains.                      |
| HW3      | Grid-stride loops for flexible kernel design, CUDA error checking, and the impact of grid/block sizing on performance; introduction to GPU profiling tools.  |
| HW4      | Efficient memory access patterns: row/column sum kernels, global memory coalescing, and using Nsight Compute for profiling and memory efficiency analysis.   |
| HW5      | Parallel reduction techniques: atomic, classical, and warp-shuffle reductions; custom reductions (e.g., max); optimizing row-wise reductions for performance.|
| HW6      | Unified Memory (UM) in CUDA: enabling data structure access on both host and device, managed memory allocation, prefetching, and performance implications.    |
| HW7      | Overlapping computation and data transfer using CUDA streams, chunked processing, and basic multi-GPU programming for concurrent kernel execution.           |
| HW8      | Memory-bound kernel optimization: analyzing and improving global/shared memory access patterns, resolving shared memory bank conflicts, and using profilers.  |
| HW9      | Cooperative groups: thread block and grid-wide synchronization, group partitioning, and advanced parallel algorithms (e.g., stream compaction with prefix sum).|
| HW10     | Advanced stream usage: chunked asynchronous processing, combining OpenMP with CUDA streams, and strategies for multi-GPU workload distribution.              |
| HW11     | Multi-Process Service (MPS): enabling concurrent multi-process GPU access, performance analysis with/without MPS, and understanding GPU resource sharing.     |
| HW12     | CUDA debugging and correctness: using compute-sanitizer and cuda-gdb to identify and fix memory errors, race conditions, and uninitialized memory usage.      |
| HW13     | CUDA Graphs: capturing and launching graphs for efficient kernel execution, stream capture, explicit graph creation, and integrating library calls (cuBLAS).  |

# Progress

The repository is updated as I progress through the course.
